apiVersion: v1
kind: Service
metadata:
  name: tensorflow-master-service
spec:
  selector:
    app: tensorflow-master
  ports:
    - protocol: TCP
      port: 12345
      targetPort: 12345
---
apiVersion: v1
kind: Service
metadata:
  name: tensorflow-worker-1-service
spec:
  selector:
    app: tensorflow-worker-1
  ports:
    - protocol: TCP
      port: 12345
      targetPort: 12345
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tensorflow-master
  labels:
    app: tensorflow-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tensorflow-master
  template:
    metadata:
      labels:
        app: tensorflow-master
    spec:
      containers:
      - name: tensorflow
        image: tensorflow/tensorflow:latest-gpu
        # This is a trick to keep the pod up and running
        command: ["/bin/bash", "-c", "--"]
        args: ["while true; do sleep 10; done;"]
        env:
        - name: TF_CONFIG
          value: '{
            "cluster": {
              "worker": [
                "$(TENSORFLOW_MASTER_SERVICE_SERVICE_HOST):$(TENSORFLOW_MASTER_SERVICE_PORT_12345_TCP_PORT)",
                "$(TENSORFLOW_WORKER_1_SERVICE_SERVICE_HOST):$(TENSORFLOW_WORKER_1_SERVICE_PORT_12345_TCP_PORT)"
              ]
            },
            "task": {"type": "worker", "index": 0}
            }'
        - name: NVIDIA_VISIBLE_DEVICES
          value: "0"
        resources:
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
        - mountPath: /workspace
          name: data
      volumes:
      - name: data
        hostPath:
          path: /workspace
          type: Directory
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tensorflow-worker-1
  labels:
    app: tensorflow-worker-1
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tensorflow-worker-1
  template:
    metadata:
      labels:
        app: tensorflow-worker-1
    spec:
      containers:
      - name: tensorflow
        image: tensorflow/tensorflow:latest-gpu
        # This is a trick to keep the pod up and running
        command: ["/bin/bash", "-c", "--"]
        args: ["while true; do sleep 10; done;"]
        env:
        - name: TF_CONFIG
          value: '{
            "cluster": {
              "worker": [
                "$(TENSORFLOW_MASTER_SERVICE_SERVICE_HOST):$(TENSORFLOW_MASTER_SERVICE_PORT_12345_TCP_PORT)",
                "$(TENSORFLOW_WORKER_1_SERVICE_SERVICE_HOST):$(TENSORFLOW_WORKER_1_SERVICE_PORT_12345_TCP_PORT)"
              ]
            },
            "task": {"type": "worker", "index": 1}
            }'
        - name: NVIDIA_VISIBLE_DEVICES
          value: "1"
        resources:
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
        - mountPath: /workspace
          name: data
      volumes:
      - name: data
        hostPath:
          path: /workspace
          type: Directory